(self.webpackChunkEVA_libre=self.webpackChunkEVA_libre||[]).push([[713],{39161:(e,t,o)=>{"use strict";o.d(t,{A:()=>s});var i=o(38685);const s=class{constructor(e,t,o){this.animationManager=e,this.apiKey=t,this.region=o,this.queue=[],this.isSpeaking=!1,this.player,this.audioConfig,this.audioInterrupt=!1,this.initSynthesizer()}initSynthesizer(){const e=this.apiKey,t=this.region,o=i.SpeechConfig.fromSubscription(e,t);o.speechSynthesisVoiceName="en-US-JennyNeural";const s=new i.SpeakerAudioDestination,n=i.AudioConfig.fromSpeakerOutput(s);this.player=s,this.audioConfig=n,this.synthesizer=new i.SpeechSynthesizer(o,this.audioConfig),this.synthesizer.visemeReceived=(e,t)=>{this.scheduleVisemeApplication(t.visemeId,t.audioOffset)}}enqueueText(e){this.queue.push(e),this.isSpeaking||this.processQueue()}processQueue(){if(0===this.queue.length)return void(this.isSpeaking=!1);this.isSpeaking=!0;const e=this.queue.shift();this.synthesizeSpeech(e).then((()=>this.processQueue()))}synthesizeSpeech(e){return new Promise(((t,o)=>{this.synthesizer.speakTextAsync(e,(e=>{console.log("Speech synthesis completed."),t(e)}),(e=>{console.log("Error during speech synthesis, restarting"),o(e)}))}))}scheduleVisemeApplication(e,t){setTimeout((()=>{this.applyVisemeToCharacter(e)}),t/1e4)}applyVisemeToCharacter(e){const t=this.animationManager.facsLib;this.audioInterrupt?(this.animationManager.setFaceToNeutral(),t.setNeutralViseme()):0===e?t.setNeutralViseme(0):(e-=1,t.setTargetViseme(e,70,0)),t.updateEngine()}stopSpeech(){this.synthesizer.close(),this.queue=[],this.isSpeaking=!1,this.initSynthesizer(),console.log("Speech synthesis stopped.")}interruptSpeech(e){this.synthesizer.close(),this.queue=[],this.isSpeaking=!1,this.initSynthesizer(),e&&this.enqueueText(e),console.log("Speech synthesis interrupted.")}}},67333:(e,t,o)=>{"use strict";o.d(t,{A:()=>i});const i=class{constructor(e){if(!e||"string"!==typeof e)throw new Error("A valid OpenAI API key must be provided.");this.apiKey=e,this.apiUrl="https://api.openai.com/v1/chat/completions"}async processText(e){const t={model:"gpt-3.5-turbo",messages:[{role:"system",content:arguments.length>1&&void 0!==arguments[1]?arguments[1]:"Answer in a professional manner:"},{role:"user",content:e}],max_tokens:150,temperature:.7};try{var o,i,s,n;const e=await fetch(this.apiUrl,{method:"POST",headers:{Authorization:"Bearer ".concat(this.apiKey),"Content-Type":"application/json"},body:JSON.stringify(t)});if(!e.ok)throw new Error("API request failed with status: ".concat(e.status));const r=null===(o=(await e.json()).choices)||void 0===o||null===(i=o[0])||void 0===i||null===(s=i.message)||void 0===s||null===(n=s.content)||void 0===n?void 0:n.trim();if(!r)throw new Error("Failed to get a valid response from the API");return r}catch(r){throw console.error("Error processing text with GPT:",r),r}}}},41226:(e,t,o)=>{"use strict";o.r(t),o.d(t,{start:()=>S,stop:()=>k});var i=o(39161),s=o(67333);let n,r,a,l,c=!1,u="",p=!1,h=!1;function g(e){e.forEach((e=>{let{id:t,intensity:o,duration:i,explanation:s=""}=e;animationManager.scheduleChange(t,90*o,i,0,s)}))}function y(){let e=[{id:"6",intensity:.4,duration:750,explanation:""},{id:"12",intensity:.5,duration:750,explanation:""}];g(e)}function d(){animationManager.setFaceToNeutral()}function w(e){return new Promise((t=>setTimeout(t,e)))}async function f(e){a.initSynthesizer();let t=await a.synthesizeSpeech(e);console.log("synthesize_result object:",t),console.log("synthesize result transcript:",e),console.log("synthesize result audioDuration:",t.audioDuration),console.log("before delay!");try{return await w(t.audioDuration/1e4),console.log("after delay!"),e}catch(o){"Delay aborted"===o.message?console.log("Delay was aborted"):console.error("Error during delay:",o)}}async function m(e,t){let o="";try{o=await t.processText(e),console.log("gptResponse: ",o)}catch(i){console.error("Error processing GPT response:",i)}try{return o&&(await f(o),l+=1),o}catch(i){console.error("Error processing TTS response:",i)}}async function S(e,t){h=!1,a=t.azure_api_key&&"string"==typeof t.azure_api_key?new i.A(e,t.azure_api_key,"eastus"):new i.A(e,t.azure_api_key.default,"eastus"),r=t.openai_api_key&&"string"==typeof t.openai_api_key?new s.A(t.openai_api_key):new s.A(t.openai_api_key.default);let o={1:"Do you like attending FIU?",2:"Where are you originally from?",3:"Do you like living in South Florida?",4:"Where would you like to go for you next vacation?",5:"Do you enjoy speaking with me?",6:"Would you speak with me again?"};console.log("questions: ".concat(o));let l=Object.keys(o).length;y(),await f("Hello, my name is eva. I will ask you ".concat(l," questions. Feel free to answer as you feel appropriate!")),d();let S={};for(let i=1;i<=l;i++){console.log("current question: ".concat(i));let e={},t=await f(o[i]);e.agent_question=t,console.log("agent_question:",t);let s=await new Promise((e=>{if("webkitSpeechRecognition"in window){if(console.log("SpeechRecognition available!"),p=!1,console.log("recognitionStop:",h),!h){c=!0,h=!1;const t=window.SpeechRecognition||window.webkitSpeechRecognition;let o;n=new t,n.continuous=!1,n.lang="en-US",n.interimResults=!0,n.maxAlternatives=1,n.onresult=async function(t){let i="",s=!1;for(let e=t.resultIndex;e<t.results.length;e++)i+=t.results[e][0].transcript,t.results[e].isFinal&&(s=!0);if(console.log("processingRequest:",p),s&&i!==u&&!p){u=i,p=!0;let t=i.toLowerCase().trim();console.log("Recognized Speech:",t),clearTimeout(o),n.stop(),p=!1,e(i)}else clearTimeout(o),o=setTimeout((()=>{console.log("No speech detected, stopping recognition."),n.stop(),e(i)}),2e3)},n.onend=()=>{console.log("Speech recognition ended."),e(u)},n.onerror=t=>{console.error("Speech recognition error:",t.error),clearTimeout(o),e(u)}}}else console.error("SpeechRecognition not available in this browser!"),e();c&&(n.start(),console.log("Speech recognition started!"))}));e.user_response=s,console.log("user_response:",s);let a="You are a helpful agent providing simple one sentence responses to user replies to your questions. Do not ask follow-up questions.\nAgent Questions: ".concat(t,"\nUser Response:").concat(s),l=await m(a,r);e.agent_response=l,console.log("agent_response:",l),S[i]=e}await f("It appears I've asked all my questions."),await f("If you'd like to review this conversation, a transcript is available in the inspector."),await f("Thanks for answering all my questions!"),y(),g([{id:"46L",intensity:.9,duration:300,explanation:""}]),await w(1e3),d();let k=JSON.stringify(S,null,2);console.log("Transaction History:\n".concat(k))}function k(){console.log("Calling stop!"),h=!0,console.log("recognitionStop:",h),c&&(n.stop(),console.log("speech recognition stopped!")),console.log("Reached end stop!")}},26308:()=>{},42250:()=>{},29645:()=>{},88632:()=>{},13678:()=>{},44573:()=>{},10952:()=>{}}]);
//# sourceMappingURL=713.7ddd3eb9.chunk.js.map