{"version":3,"file":"static/js/145.962605e1.chunk.js","mappings":"mHAuDE,QAvDF,MACIA,WAAAA,CAAYC,GACV,IAAKA,GAA4B,kBAAXA,EACpB,MAAM,IAAIC,MAAM,4CAElBC,KAAKF,OAASA,EACdE,KAAKC,OAAS,4CAChB,CAQA,iBAAMC,CAAYC,GAChB,MAAMC,EAAU,CACdC,MAAO,gBACPC,SAAU,CACR,CAAEC,KAAM,SAAUC,QAJWC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,oCAKhC,CAAEF,KAAM,OAAQC,QAASL,IAE3BS,WAAY,IACZC,YAAa,IAGf,IAAK,IAADC,EAAAC,EAAAC,EAAAC,EACF,MAAMC,QAAiBC,MAAMnB,KAAKC,OAAQ,CACxCmB,OAAQ,OACRC,QAAS,CACP,cAAgB,UAADC,OAAYtB,KAAKF,QAChC,eAAgB,oBAElByB,KAAMC,KAAKC,UAAUrB,KAGvB,IAAKc,EAASQ,GACZ,MAAM,IAAI3B,MAAM,mCAADuB,OAAoCJ,EAASS,SAG9D,MACMC,EAA0B,QAAfd,SADEI,EAASW,QACHC,eAAO,IAAAhB,GAAK,QAALC,EAAZD,EAAe,UAAE,IAAAC,GAAS,QAATC,EAAjBD,EAAmBgB,eAAO,IAAAf,GAAS,QAATC,EAA1BD,EAA4BR,eAAO,IAAAS,OAAvB,EAAZA,EAAqCe,OAEzD,IAAKJ,EACH,MAAM,IAAI7B,MAAM,+CAGlB,OAAO6B,CACT,CAAE,MAAOK,GAEP,MADAC,QAAQD,MAAM,kCAAmCA,GAC3CA,CACR,CACF,E,mCCpDW,MAAME,EACjBtC,WAAAA,GACIG,KAAKoC,YAAc,KACnBpC,KAAKqC,aAAc,CACvB,CAEAC,oBAAAA,GACI,MAAM,4BAA6BC,QAKnCvC,KAAKoC,YAAc,IAAIG,OAAOC,wBAC9BxC,KAAKoC,YAAYK,YAAa,EAC9BzC,KAAKoC,YAAYM,gBAAiB,EAClC1C,KAAKoC,YAAYO,KAAO,QAEjBC,QAAQC,YATXX,QAAQD,MAAM,iDACPW,QAAQE,OAAO,gCAS9B,CAEAC,0BAAAA,CAA2BC,GACvB,IAAIhD,KAAKqC,YAKT,OAAO,IAAIO,SAAQ,CAACC,EAASC,KACzB9C,KAAKsC,uBAAuBW,MAAK,KAC7BjD,KAAKoC,YAAYc,SAAYC,IACzB,MAAMC,EAAaC,MAAMC,KAAKH,EAAMI,SAC/BC,KAAIC,GAAUA,EAAO,GAAGL,aACxBM,KAAK,IACVxB,QAAQyB,IAAI,eAADrC,OAAgB8B,EAAWpB,SACtCgB,EAAqBI,EAAWpB,OAAO,EAG3ChC,KAAKoC,YAAYwB,QAAWT,IACxBjB,QAAQD,MAAM,4BAA6BkB,EAAMlB,OAE7B,cAAhBkB,EAAMlB,OACNC,QAAQ2B,KAAK,6CACbC,YAAW,KACP9D,KAAKoC,YAAY2B,OAAO,GACzB,MAEHjB,EAAOK,EAAMlB,MACjB,EAGJjC,KAAKoC,YAAY4B,MAAQ,KACrB9B,QAAQyB,IAAI,2CACR3D,KAAKqC,aACLrC,KAAKoC,YAAY2B,OACrB,EAGJ/D,KAAKqC,aAAc,EACnBrC,KAAKoC,YAAY2B,QACjBlB,GAAS,IACVoB,OAAMhC,IACLC,QAAQD,MAAM,yCAA0CA,GACxDa,EAAOb,EAAM,GACf,IAxCFC,QAAQ2B,KAAK,kCA0CrB,CAEAK,eAAAA,GACQlE,KAAKoC,cACLpC,KAAKqC,aAAc,EACnBrC,KAAKoC,YAAY+B,OACjBjC,QAAQyB,IAAI,wBAEpB,E,yGCxEW,MAAMS,EACnBvE,WAAAA,CAAYwE,GACR,GAAIhB,MAAMiB,QAAQD,GACdrE,KAAKqE,QAAUA,EAAQX,KAAK,SACzB,IAAuB,kBAAZW,EAGd,MAAM,IAAItE,MAAM,0DAFhBC,KAAKqE,QAAUA,CAGnB,CACArE,KAAKuE,mBAAqB,IAC9B,CAEAC,MAAAA,CAAOrE,GACH,OAAO,IAAIyC,SAASC,IAChB,MAAM4B,EAAiBzE,KAAK0E,oBAAoBvE,GAC5CsE,GACAzE,KAAKuE,mBAAqBE,EAC1B5B,EAAQ4B,IAER5B,EAAQ,KACZ,GAER,CAEA6B,mBAAAA,CAAoBvE,GAChB,OAAOH,KAAKqE,QAAQM,SAASxE,EAAKyE,eAAiBzE,EAAO,IAC9D,ECxBa,MAAM0E,UAAmCT,EACpDvE,WAAAA,CAAYiF,GAAiD,IAAjCC,EAAUtE,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,IAAMuE,EAAWvE,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EACtDsE,MAAMH,GACN9E,KAAKkF,kBAAmB,EACxBlF,KAAKuE,mBAAqB,KAC1BvE,KAAKgF,YAAcA,EACnBhF,KAAKmF,cAAgB,KACrBnF,KAAK+E,WAAaA,CACtB,CAEAK,cAAAA,CAAepC,GACXhD,KAAKgF,YAAYjC,2BAA2BC,EAChD,CAEAqC,aAAAA,GACIrF,KAAKgF,YAAYd,iBACrB,CAGAoB,eAAAA,CAAgBnF,GACZ,OAAO,IAAIyC,SAASC,IACZ7C,KAAKkF,kBACLlF,KAAKkF,kBAAmB,EACxBrC,EAAQ,CAAE0C,OAAQvF,KAAKuE,mBAAoBiB,SAAUrF,IACrDH,KAAKuE,mBAAqB,MAE1BU,MAAMT,OAAOrE,GACR8C,MAAKwB,IACEA,GACAzE,KAAKkF,kBAAmB,EACxBlF,KAAKuE,mBAAqBE,EAC1B5B,EAAQ,CAAE0C,OAAQd,EAAgBe,SAAU,QAE5C3C,EAAQ,KACZ,GAEZ,GAER,CAGA4C,4BAAAA,CAA6BC,EAAW1C,GACpCc,YAAW,KACP4B,EAAU,aACV1F,KAAKoF,eAAepC,EAAqB,GAC1ChD,KAAK+E,WACZ,CAGAY,gBAAAA,CAAiBC,GACb,MACMC,EAAkB,GACxB,IAAIC,EAAe,GAenB,OAbAF,EAAUG,MAAM,KAAKC,SAAQC,IACrBH,EAAapF,OAASuF,EAAKvF,OAAS,EAL1B,KAMVmF,EAAgBK,KAAKJ,GACrBA,EAAeG,GAEfH,IAAyC,IAAxBA,EAAapF,OAAe,GAAK,KAAOuF,CAC7D,IAGAH,EAAapF,OAAS,GACtBmF,EAAgBK,KAAKJ,GAGlBD,CACX,E,iFCnEJ,MA+BA,EA/B8BM,IAAiB,IAAhB,OAAExE,GAAQwE,EAOvC,OACEC,EAAAA,EAAAA,KAACC,EAAAA,GAAG,CACFC,SAAS,QACTC,OAAO,OACPC,OAAO,OACPC,KAAK,OACLC,GAAG,WACHC,aAAa,KACbC,EAAG,EACHC,UAAU,KACVC,WAAW,OAAMC,UAEjBC,EAAAA,EAAAA,MAACX,EAAAA,GAAG,CAACY,QAAQ,OAAOC,cAAc,SAASC,WAAW,SAAQJ,SAAA,EAC5DX,EAAAA,EAAAA,KAACgB,EAAAA,EAAI,CAACC,GAAIC,EAAAA,IAAUC,MAnBX,CACbC,QAAS,UACTC,UAAW,YACXC,KAAM,cAgBgC/F,GAASgG,QAAS,EAAGC,GAAI,KAC3DZ,EAAAA,EAAAA,MAACa,EAAAA,EAAI,CAACN,MAAM,QAAQO,WAAW,OAAMf,SAAA,CACvB,YAAXpF,GAAwB,UACb,cAAXA,GAA0B,YACf,SAAXA,GAAqB,cAGtB,ECrBV,IAAIqD,EACA+C,EACAC,EACAC,EACAC,GAAsB,EACtBC,GAAW,EACXC,EAAc,GACdC,EAAO,KACX,MAAMC,EAAmB,IAuBnBC,EAAoBA,CAACC,EAAkBC,KACzC,MAAM3D,EAAiB2D,EAAY3D,gBAAkB,GAC/ChF,EAAS2I,EAAY3I,OAQ3B,OANAkF,EAAc,IAAI7C,EAAAA,EAAY,aAC9B4F,EAA6B,IAAIlD,EAA2BC,EAAgBwD,EAAkBtD,GAC9FgD,EAAgB,IAAIU,EAAAA,EAAoB5I,GACxCmI,EAAeU,EAAAA,EAAaC,YAAYJ,GA1B1BK,EA6BE,WA5BT,IAAIjG,SAASC,IAChBX,QAAQyB,IAAI,kCAADrC,OAAmCuH,EAAS,QACvD,MAAMC,EAAcA,KAChB,MAAMC,EAAgBd,EAAae,YAAYC,MAAKC,GAASA,EAAMC,KAAKxE,SAASkE,KAC7EE,GACAd,EAAamB,SAASL,EAAcI,MACpCjH,QAAQyB,IAAI,cAADrC,OAAeyH,EAAcI,OACxCtG,MAEAX,QAAQyB,IAAI,GAADrC,OAAIuH,EAAS,kCACxB/E,WAAWgF,EAAa,KAC5B,EAEJA,GAAa,IAdHD,KA6Ba,EASzBQ,EAA2BnI,IAC7B,MAAMoI,EAAS,GACf,IAAIxD,EAAe,GAenB,OAbA5E,EAAS6E,MAAM,KAAKC,SAAQC,IACpBH,EAAapF,OAASuF,EAAKvF,OAAS,EA9CrB,KA+Cf4I,EAAOpD,KAAKJ,GACZA,EAAeG,GAEfH,IAAyC,IAAxBA,EAAapF,OAAe,GAAK,KAAOuF,CAC7D,IAGAH,EAAapF,OAAS,GACtB4I,EAAOpD,KAAKJ,GAGTwD,CAAM,EAIXC,EAAwBA,CAACpJ,EAAMuF,EAAW8D,KA1BtBrJ,IACfiI,GAAejI,EAAKwE,SAASyD,GA0BhCqB,CAAiBtJ,GACjB+B,QAAQyB,IAAI,sCAIhBzB,QAAQyB,IAAI,qBAADrC,OAAsBnB,IACjCqJ,EAAM,CACFE,MAAO,mBACPC,YAAaxJ,EACbwB,OAAQ,OACRiI,SAAU,MAIT1B,EAGD2B,EAAe1J,EAAMuF,EAAW8D,GAFhCM,EAAoB3J,EAAMuF,EAAW8D,GAGzC,EAIEM,EAAsBA,CAACC,EAAerE,EAAW8D,KACnDtB,GAAsB,EACtBE,EAAc,+BACdD,GAAW,EAEXJ,EAA2B1C,gBAG3B4C,EAAa+B,YAAY5B,GACzB1C,EAAU,WAEV8D,EAAM,CACFE,MAAO,mBACPC,YAAY,cAADrI,OAAiByI,EAAa,oBACzCpI,OAAQ,UACRiI,SAAU,MAGd5B,EAAc9H,YAAY6J,EAAe,qBACpC9G,MAAK/B,IACF,GAAIA,EAAU,CACSmI,EAAwBnI,GAChC8E,SAAQJ,IAEfqC,EAAa+B,YAAYpE,EAAU,IAEvCwC,EAAclH,CAClB,CAEAwE,EAAU,QACVyC,GAAW,EAEXrE,YAAW,KACP5B,QAAQyB,IAAI,gDACZoE,EAA2BtC,6BAA6BC,GAAYvF,GAASoJ,EAAsBpJ,EAAMuF,EAAW8D,IAAO,GAC5HlB,EAAiB,IAEvBrE,OAAMhC,IACHC,QAAQD,MAAM,mCAAoCA,GAClD8F,EAA2BtC,6BAA6BC,GAAYvF,GAASoJ,EAAsBpJ,EAAMuF,EAAW8D,IAAO,GAC7H,EAIJK,EAAiBA,CAACI,EAAcvE,EAAW8D,KAC7CrB,GAAW,EACXJ,EAA2B1C,gBAE3B2C,EAAc9H,YAAY+J,EAAc,qBACnChH,MAAK/B,IACF,GAAIA,EAAU,CACSmI,EAAwBnI,GAChC8E,SAAQJ,IAEfqC,EAAa+B,YAAYpE,EAAU,IAEvCwC,EAAclH,CAClB,CAEAwE,EAAU,QACVyC,GAAW,EAEXrE,YAAW,KACP5B,QAAQyB,IAAI,yCACZoE,EAA2BtC,6BAA6BC,GAAYvF,GAASoJ,EAAsBpJ,EAAMuF,EAAW8D,IAAO,GAC5HlB,EAAiB,IAEvBrE,OAAMhC,IACHC,QAAQD,MAAM,8BAA+BA,GAC7C8F,EAA2BtC,6BAA6BC,GAAYvF,GAASoJ,EAAsBpJ,EAAMuF,EAAW8D,IAAO,GAC7H,EAIGzF,EAAQA,CAACyE,EAAkBC,EAAayB,KAC5CA,GAAiBA,EAAaC,QAKnC5B,EAAkBC,EAAkBC,GAC/BxF,MAAK,KACF,MAAMmH,EAAUA,KACZ,MAAOzI,EAAQ+D,IAAa2E,EAAAA,EAAAA,UAAS,QAC/Bb,GAAQc,EAAAA,EAAAA,KAUd,OARAC,EAAAA,EAAAA,YAAU,KACNxC,EAA2B3C,gBAAgBjF,GAASoJ,EAAsBpJ,EAAMuF,EAAW8D,KAEpF,KACHxE,EAAYd,iBAAiB,IAElC,CAACwB,EAAW8D,KAERpD,EAAAA,EAAAA,KAACoE,EAAqB,CAAC7I,OAAQA,GAAU,EAG/C0G,IACDA,EAAOoC,EAAAA,WAA0BP,EAAaC,UAGlD9B,EAAKqC,QAAOtE,EAAAA,EAAAA,KAACgE,EAAO,IAAI,IAzB5BlI,QAAQD,MAAM,8BA0BZ,EAIGkC,EAAOA,KACZa,GACAA,EAAYd,kBAEZ+D,GACAA,EAAa0C,aAEbtC,IACAA,EAAKuC,UACLvC,EAAO,KACX,C","sources":["VISOS/cognition/TextToGptReconciler.js","VISOS/perception/audio/AudioToText.js","VISOS/perception/audio/TextToListener.js","VISOS/perception/audio/TextToListenerWithFollowUp.js","components/TrafficLightIndicator.jsx","modules/chat.js"],"sourcesContent":["class TextToGptReconciler {\n    constructor(apiKey) {\n      if (!apiKey || typeof apiKey !== 'string') {\n        throw new Error('A valid OpenAI API key must be provided.');\n      }\n      this.apiKey = apiKey;\n      this.apiUrl = 'https://api.openai.com/v1/chat/completions';\n    }\n  \n    /**\n     * Processes the provided text by sending it to the OpenAI API.\n     * @param {string} text - The input text to process.\n     * @param {string} instruction - Instruction or system prompt for the AI.\n     * @returns {Promise<string>} - The GPT response.\n     */\n    async processText(text, instruction = 'Answer in a professional manner:') {\n      const payload = {\n        model: 'gpt-3.5-turbo',  // You can switch this model based on your requirement\n        messages: [\n          { role: 'system', content: instruction },\n          { role: 'user', content: text }\n        ],\n        max_tokens: 150,  // Adjust as necessary\n        temperature: 0.7\n      };\n  \n      try {\n        const response = await fetch(this.apiUrl, {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.apiKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify(payload)\n        });\n  \n        if (!response.ok) {\n          throw new Error(`API request failed with status: ${response.status}`);\n        }\n  \n        const data = await response.json();\n        const gptResponse = data.choices?.[0]?.message?.content?.trim();\n  \n        if (!gptResponse) {\n          throw new Error('Failed to get a valid response from the API');\n        }\n  \n        return gptResponse;\n      } catch (error) {\n        console.error('Error processing text with GPT:', error);\n        throw error;\n      }\n    }\n  }\n  \n  export default TextToGptReconciler;","export default class AudioToText {\n    constructor() {\n        this.recognition = null;\n        this.isListening = false;\n    }\n\n    initializeRecognizer() {\n        if (!('webkitSpeechRecognition' in window)) {\n            console.error('Web Speech API not supported in this browser.');\n            return Promise.reject('Web Speech API not supported');\n        }\n\n        this.recognition = new window.webkitSpeechRecognition();\n        this.recognition.continuous = true;  // Continuous listening mode\n        this.recognition.interimResults = false;  // Final results only\n        this.recognition.lang = 'en-US';  // Set language\n\n        return Promise.resolve();\n    }\n\n    startContinuousRecognition(onRecognizedCallback) {\n        if (this.isListening) {\n            console.warn('Recognition is already running.');\n            return;\n        }\n\n        return new Promise((resolve, reject) => {\n            this.initializeRecognizer().then(() => {\n                this.recognition.onresult = (event) => {\n                    const transcript = Array.from(event.results)\n                        .map(result => result[0].transcript)\n                        .join('');\n                    console.log(`RECOGNIZED: ${transcript.trim()}`);\n                    onRecognizedCallback(transcript.trim());\n                };\n\n                this.recognition.onerror = (event) => {\n                    console.error('Speech recognition error:', event.error);\n                    // Handle specific error types\n                    if (event.error === 'no-speech') {\n                        console.warn('No speech detected, resuming listening...');\n                        setTimeout(() => {\n                            this.recognition.start(); // Restart recognition after a short delay\n                        }, 1000); // Adjust delay as necessary\n                    } else {\n                        reject(event.error);\n                    }\n                };\n\n                this.recognition.onend = () => {\n                    console.log('Speech recognition ended, restarting...');\n                    if (this.isListening) {\n                        this.recognition.start(); // Restart if recognition stops\n                    }\n                };\n\n                this.isListening = true;\n                this.recognition.start();\n                resolve();\n            }).catch(error => {\n                console.error('Error initializing speech recognition:', error);\n                reject(error);\n            });\n        });\n    }\n\n    stopRecognition() {\n        if (this.recognition) {\n            this.isListening = false;\n            this.recognition.stop();\n            console.log('Recognition stopped.');\n        }\n    }\n}","export default class TextToListener {\n  constructor(phrases) {\n      if (Array.isArray(phrases)) {\n          this.phrases = phrases.join(' '); // Convert the array of phrases into a single string\n      } else if (typeof phrases === 'string') {\n          this.phrases = phrases;\n      } else {\n          throw new Error('Phrases must be either a string or an array of strings');\n      }\n      this.lastDetectedPhrase = null;\n  }\n\n  listen(text) {\n      return new Promise((resolve) => {\n          const detectedPhrase = this.detectTriggerPhrase(text);\n          if (detectedPhrase) {\n              this.lastDetectedPhrase = detectedPhrase;\n              resolve(detectedPhrase);\n          } else {\n              resolve(null);\n          }\n      });\n  }\n\n  detectTriggerPhrase(text) {\n      return this.phrases.includes(text.toLowerCase()) ? text : null;\n  }\n}","import TextToListener from './TextToListener';\n\nexport default class TextToListenerWithFollowUp extends TextToListener {\n    constructor(triggerPhrases, bufferTime = 1000, audioToText) {\n        super(triggerPhrases);\n        this.awaitingFollowUp = false;\n        this.lastDetectedPhrase = null;\n        this.audioToText = audioToText;  // Pass the AudioToText instance\n        this.debounceTimer = null;\n        this.bufferTime = bufferTime;  // Buffer time to debounce follow-up detection\n    }\n\n    startListening(onRecognizedCallback) {\n        this.audioToText.startContinuousRecognition(onRecognizedCallback);\n    }\n\n    stopListening() {\n        this.audioToText.stopRecognition();\n    }\n\n    // Handle the incoming utterances as a stream\n    listenForStream(text) {\n        return new Promise((resolve) => {\n            if (this.awaitingFollowUp) {\n                this.awaitingFollowUp = false;\n                resolve({ phrase: this.lastDetectedPhrase, followUp: text });\n                this.lastDetectedPhrase = null;\n            } else {\n                super.listen(text)\n                    .then(detectedPhrase => {\n                        if (detectedPhrase) {\n                            this.awaitingFollowUp = true;\n                            this.lastDetectedPhrase = detectedPhrase;\n                            resolve({ phrase: detectedPhrase, followUp: null });\n                        } else {\n                            resolve(null);\n                        }\n                    });\n            }\n        });\n    }\n\n    // Add the resumeListeningAfterResponse method\n    resumeListeningAfterResponse(setStatus, onRecognizedCallback) {\n        setTimeout(() => {\n            setStatus('listening');  // Update the UI to show that it's listening\n            this.startListening(onRecognizedCallback);  // Resume listening\n        }, this.bufferTime);  // Resume listening after the specified buffer time\n    }\n\n    // Handle long responses by splitting them into smaller utterances\n    processUtterance(utterance) {\n        const maxLength = 120;  // Define the max length for each chunk\n        const utteranceChunks = [];\n        let currentChunk = '';\n\n        utterance.split(' ').forEach(word => {\n            if (currentChunk.length + word.length + 1 > maxLength) {\n                utteranceChunks.push(currentChunk);\n                currentChunk = word;\n            } else {\n                currentChunk += (currentChunk.length === 0 ? '' : ' ') + word;\n            }\n        });\n\n        if (currentChunk.length > 0) {\n            utteranceChunks.push(currentChunk);\n        }\n\n        return utteranceChunks;\n    }\n}","import { Box, Icon, Text } from '@chakra-ui/react';\nimport { FaCircle } from 'react-icons/fa';\n\nconst TrafficLightIndicator = ({ status }) => {\n  const colors = {\n    talking: 'red.500',\n    listening: 'green.500',\n    idle: 'yellow.500',\n  };\n\n  return (\n    <Box\n      position=\"fixed\"\n      zIndex=\"1000\" // High z-index to ensure visibility\n      bottom=\"20px\"\n      left=\"20px\"\n      bg=\"gray.700\"\n      borderRadius=\"md\"\n      p={4}\n      boxShadow=\"xl\"\n      userSelect=\"none\"\n    >\n      <Box display=\"flex\" flexDirection=\"column\" alignItems=\"center\">\n        <Icon as={FaCircle} color={colors[status]} boxSize={6} mb={2} />\n        <Text color=\"white\" fontWeight=\"bold\">\n          {status === 'talking' && 'Talking'}\n          {status === 'listening' && 'Listening'}\n          {status === 'idle' && 'Idle'}\n        </Text>\n      </Box>\n    </Box>\n  );\n};\n\nexport default TrafficLightIndicator;","import ReactDOMClient from 'react-dom/client';\nimport React, { useState, useEffect } from 'react';\nimport { useToast } from '@chakra-ui/react';\nimport AudioToText from './../VISOS/perception/audio/AudioToText';\nimport TextToListenerWithFollowUp from './../VISOS/perception/audio/TextToListenerWithFollowUp';\nimport TextToGptReconciler from './../VISOS/cognition/TextToGptReconciler';\nimport VoiceManager from './../VISOS/action/verbalizers/VoiceManager';\nimport TrafficLightIndicator from '../components/TrafficLightIndicator';\n\nlet audioToText;\nlet textToListenerWithFollowUp;\nlet gptReconciler;\nlet voiceManager;\nlet conversationStarted = false; // Track conversation state\nlet speaking = false;\nlet agentSpeech = ''; // Track agent's last spoken phrase\nlet root = null;\nconst listenBufferTime = 2000; // Buffer time to resume listening after speaking\nconst maxUtteranceLength = 120; // Max characters per utterance\n\n// Function to set the voice to a specific voice and ensure it's available\nconst setVoice = (voiceName) => {\n    return new Promise((resolve) => {\n        console.log(`Attempting to set the voice to ${voiceName}...`);\n        const checkVoices = () => {\n            const selectedVoice = voiceManager.getVoices().find(voice => voice.name.includes(voiceName));\n            if (selectedVoice) {\n                voiceManager.setVoice(selectedVoice.name);\n                console.log(`Voice set: ${selectedVoice.name}`);\n                resolve();\n            } else {\n                console.log(`${voiceName} voice not found, retrying...`);\n                setTimeout(checkVoices, 500);  // Retry until the voice is available\n            }\n        };\n        checkVoices();\n    });\n};\n\n// Initialize necessary modules\nconst initializeModules = (animationManager, appSettings) => {\n    const triggerPhrases = appSettings.triggerPhrases || [];\n    const apiKey = appSettings.apiKey;\n\n    audioToText = new AudioToText('webspeech');\n    textToListenerWithFollowUp = new TextToListenerWithFollowUp(triggerPhrases, listenBufferTime, audioToText);\n    gptReconciler = new TextToGptReconciler(apiKey);\n    voiceManager = VoiceManager.getInstance(animationManager);\n\n    // Set the voice to \"Samantha\" (or whatever voice is preferred)\n    return setVoice('Samantha');\n};\n\n// Ensure the agent does not respond to its own speech\nconst shouldIgnoreText = (text) => {\n    return agentSpeech && text.includes(agentSpeech);\n};\n\n// Break response into smaller utterances\nconst breakResponseIntoChunks = (response) => {\n    const chunks = [];\n    let currentChunk = '';\n\n    response.split(' ').forEach(word => {\n        if (currentChunk.length + word.length + 1 > maxUtteranceLength) {\n            chunks.push(currentChunk);\n            currentChunk = word;\n        } else {\n            currentChunk += (currentChunk.length === 0 ? '' : ' ') + word;\n        }\n    });\n\n    if (currentChunk.length > 0) {\n        chunks.push(currentChunk);\n    }\n\n    return chunks;\n};\n\n// Handle transcribed text and restart listening\nconst handleTranscribedText = (text, setStatus, toast) => {\n    if (shouldIgnoreText(text)) {\n        console.log('Ignoring agentâ€™s own speech.');\n        return;\n    }\n\n    console.log(`Transcribed text: ${text}`);\n    toast({\n        title: 'Transcribed text',\n        description: text,\n        status: 'info',\n        duration: 2000,\n    });\n\n    // Handle trigger and follow-ups differently\n    if (!conversationStarted) {\n        handleTriggerPhrase(text, setStatus, toast);\n    } else {\n        handleFollowUp(text, setStatus, toast);\n    }\n};\n\n// Handle the initial trigger phrase and start the conversation\nconst handleTriggerPhrase = (triggerPhrase, setStatus, toast) => {\n    conversationStarted = true; // Mark conversation as started\n    agentSpeech = \"Let me check that for you...\";\n    speaking = true;\n\n    textToListenerWithFollowUp.stopListening();\n\n    // Use the currently selected voice from the VoiceManager\n    voiceManager.enqueueText(agentSpeech);\n    setStatus('talking');\n\n    toast({\n        title: 'Trigger Detected',\n        description: `You said: \\\"${triggerPhrase}\\\". Processing...`,\n        status: 'success',\n        duration: 3000,\n    });\n\n    gptReconciler.processText(triggerPhrase, 'Answer seriously:')\n        .then(response => {\n            if (response) {\n                const utterances = breakResponseIntoChunks(response);\n                utterances.forEach(utterance => {\n                    // Use the currently selected voice for each utterance\n                    voiceManager.enqueueText(utterance);\n                });\n                agentSpeech = response;\n            }\n\n            setStatus('idle');\n            speaking = false;\n\n            setTimeout(() => {\n                console.log(\"Resuming listening after trigger response...\");\n                textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n            }, listenBufferTime); // Adjust buffer time if necessary\n        })\n        .catch(error => {\n            console.error(\"Error processing trigger phrase:\", error);\n            textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n        });\n};\n\n// Handle follow-up text after the conversation has started\nconst handleFollowUp = (followUpText, setStatus, toast) => {\n    speaking = true;\n    textToListenerWithFollowUp.stopListening();\n\n    gptReconciler.processText(followUpText, 'Answer seriously:')\n        .then(response => {\n            if (response) {\n                const utterances = breakResponseIntoChunks(response);\n                utterances.forEach(utterance => {\n                    // Use the currently selected voice for each utterance\n                    voiceManager.enqueueText(utterance);\n                });\n                agentSpeech = response;\n            }\n\n            setStatus('idle');\n            speaking = false;\n\n            setTimeout(() => {\n                console.log(\"Resuming listening after follow-up...\");\n                textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n            }, listenBufferTime); // Adjust buffer time if necessary\n        })\n        .catch(error => {\n            console.error(\"Error processing follow-up:\", error);\n            textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n        });\n};\n\n// Start the chat app\nexport const start = (animationManager, appSettings, containerRef) => {\n    if (!containerRef || !containerRef.current) {\n        console.error('Invalid container reference');\n        return;\n    }\n\n    initializeModules(animationManager, appSettings)\n        .then(() => {\n            const ChatApp = () => {\n                const [status, setStatus] = useState('idle');\n                const toast = useToast();\n\n                useEffect(() => {\n                    textToListenerWithFollowUp.startListening((text) => handleTranscribedText(text, setStatus, toast));\n\n                    return () => {\n                        audioToText.stopRecognition();\n                    };\n                }, [setStatus, toast]);\n\n                return <TrafficLightIndicator status={status} />;\n            };\n\n            if (!root) {\n                root = ReactDOMClient.createRoot(containerRef.current);\n            }\n\n            root.render(<ChatApp />);\n        });\n};\n\n// Stop the chat app\nexport const stop = () => {\n    if (audioToText) {\n        audioToText.stopRecognition();\n    }\n    if (voiceManager) {\n        voiceManager.stopSpeech();\n    }\n    if (root) {\n        root.unmount();\n        root = null;\n    }\n};"],"names":["constructor","apiKey","Error","this","apiUrl","processText","text","payload","model","messages","role","content","arguments","length","undefined","max_tokens","temperature","_data$choices","_data$choices$","_data$choices$$messag","_data$choices$$messag2","response","fetch","method","headers","concat","body","JSON","stringify","ok","status","gptResponse","json","choices","message","trim","error","console","AudioToText","recognition","isListening","initializeRecognizer","window","webkitSpeechRecognition","continuous","interimResults","lang","Promise","resolve","reject","startContinuousRecognition","onRecognizedCallback","then","onresult","event","transcript","Array","from","results","map","result","join","log","onerror","warn","setTimeout","start","onend","catch","stopRecognition","stop","TextToListener","phrases","isArray","lastDetectedPhrase","listen","detectedPhrase","detectTriggerPhrase","includes","toLowerCase","TextToListenerWithFollowUp","triggerPhrases","bufferTime","audioToText","super","awaitingFollowUp","debounceTimer","startListening","stopListening","listenForStream","phrase","followUp","resumeListeningAfterResponse","setStatus","processUtterance","utterance","utteranceChunks","currentChunk","split","forEach","word","push","_ref","_jsx","Box","position","zIndex","bottom","left","bg","borderRadius","p","boxShadow","userSelect","children","_jsxs","display","flexDirection","alignItems","Icon","as","FaCircle","color","talking","listening","idle","boxSize","mb","Text","fontWeight","textToListenerWithFollowUp","gptReconciler","voiceManager","conversationStarted","speaking","agentSpeech","root","listenBufferTime","initializeModules","animationManager","appSettings","TextToGptReconciler","VoiceManager","getInstance","voiceName","checkVoices","selectedVoice","getVoices","find","voice","name","setVoice","breakResponseIntoChunks","chunks","handleTranscribedText","toast","shouldIgnoreText","title","description","duration","handleFollowUp","handleTriggerPhrase","triggerPhrase","enqueueText","followUpText","containerRef","current","ChatApp","useState","useToast","useEffect","TrafficLightIndicator","ReactDOMClient","render","stopSpeech","unmount"],"sourceRoot":""}